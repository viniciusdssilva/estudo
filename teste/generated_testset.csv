user_input,reference_contexts,reference,synthesizer_name
How does Weave manage the execution speed of Op calls while capturing detailed system and client information?,"['<1-hop>\n\nHow can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_system_info"": False}).\n\nHow can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_client_info"": False}).\n\nWill Weave affect my function\'s execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM. To minimize Weave\'s impact on the speed of your Op\'s execution, its network activity happens on a background thread. When your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\nHow is Weave data ingestion calculated?', '<2-hop>\n\nOp call hierarchy - When an Op is called within the context of another Op executing, this relationship is captured, even in cases where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a ""Trace tree"".\n\nExecution status and exceptions - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\nSystem information - Weave may capture information about which operating system the client is running on including detailed version information.\n\nClient information - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.']","Weave manages the execution speed of Op calls by ensuring that its network activity occurs on a background thread, which minimizes its impact on the speed of the Op's execution. This is important because Weave captures detailed system and client information, such as the operating system details and the programming language in use. Despite this data capture, the overhead of Weave logging is typically negligible compared to making a call to an LLM. However, when the program is exiting, it may pause while any remaining enqueued data is logged.",multi_hop_specific_query_synthesizer
"How does the Weave Python SDK facilitate the redaction of Personally Identifiable Information (PII) in enterprise environments, and what role does the Python SDK play in the versioning and tracking of Weave operations?","[""<1-hop>\n\nimport Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init('intro-example')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don't call `weave.init('your-project-name')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from 'weave'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)"", '<2-hop>\n\nRedact PII from Traces\n\n:::important This feature is only available for Enterprise users, and is only accessible via the Python SDK. :::\n\nSome organizations process Personally Identifiable Information (PII) such as names, phone numbers, and email addresses in their Large Language Model (LLM) workflows. Storing this data in Weights & Biases (W&B) Weave poses compliance and security risks.\n\nThe Sensitive Data Protection feature allows you to automatically redact Personally Identifiable Information (PII) from a trace before it is sent to Weave servers. This feature integrates Microsoft Presidio into the Weave Python SDK, which means that you can control redaction settings at the SDK level.\n\nThe Sensitive Data Protection feature introduces the following functionality to the Python SDK:\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.']","The Weave Python SDK facilitates the redaction of Personally Identifiable Information (PII) in enterprise environments by integrating Microsoft Presidio, which allows users to control redaction settings at the SDK level. This is achieved through the Sensitive Data Protection feature, which introduces a redact_pii setting that can be toggled on or off in the weave.init call to enable automatic redaction of common entities. Additionally, the Python SDK plays a crucial role in the versioning and tracking of Weave operations by allowing functions decorated with @weave.op() to automatically log all calls and create new op versions if the code changes from the last call. This ensures that inputs and outputs of the function are logged, providing a comprehensive tracking mechanism.",multi_hop_specific_query_synthesizer
How does Weave utilize code capture and Op call hierarchy to improve the evaluation of language models?,"[""<1-hop>\n\nCode capture - Weave captures a representation of the Op's source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged."", '<2-hop>\n\nOp call hierarchy - When an Op is called within the context of another Op executing, this relationship is captured, even in cases where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a ""Trace tree"".\n\nExecution status and exceptions - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\nSystem information - Weave may capture information about which operating system the client is running on including detailed version information.\n\nClient information - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.']","Weave utilizes code capture by recording a representation of the Op's source code, including inline comments and the values of variables or sources of non-Op functions called. This allows for understanding the evaluation of code over time, even if changes are not saved to the source control system. Additionally, the Op call hierarchy is captured, which records the relationship between Op calls, even when intermediate non-Op functions are executed. This information is used to provide a 'Trace tree,' which helps in evaluating and improving the performance of language models by offering insights into the execution flow and dependencies.",multi_hop_specific_query_synthesizer
How can you create a human annotation scorer using the API and UI in Weave?,"['<1-hop>\n\nOpen the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\n5. Make an annotation. 6. Click Save. 7. In the call details page, click Feedback to view the calls table. The new annotation displays in the table. You can also view the annotations in the Annotations column in the call table in Traces.\n\nRefresh the call table to view the most up-to-date information.\n\nCreate a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.', '<2-hop>\n\nDelete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations\n\nHuman annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the UI or the API. Then, you can use the scorer in the UI to make annotations, and modify your annotation scorers using the API.\n\nCreate a human annotation scorer in the UI\n\nTo create a human annotation scorer in the UI, do the following:\n\nIn the sidebar, navigate to Scorers.\n\nIn the upper right corner, click + Create scorer.\n\nIn the configuration page, set:\n\nScorer type to Human annotation\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.']","To create a human annotation scorer using the API in Weave, you need to import the AnnotationSpec class from weave.flow.annotation_spec and use the save method on the weave client to create the scorer. Each scorer is its own object, created and updated independently. Alternatively, to create a human annotation scorer in the UI, navigate to Scorers in the sidebar, click + Create scorer in the upper right corner, and set the configuration page with the scorer type as Human annotation, along with a name, description, and type of feedback to be collected. Then, click Create scorer to finalize the process.",multi_hop_specific_query_synthesizer
How you make and update human annotation scorer using API and where you see changes?,"['<1-hop>\n\nModify a human annotation scorer using the API\n\nExpanding on creating a human annotation scorer using the API, the following example creates an updated version of the Temperature scorer, by using the original object ID (temperature-scorer) on save. The result is an updated object, with a history of all versions.\n\nYou can view human annotation scorer object history in the Scorers tab under Human annotations.\n\napi = weave.init(""feedback-example"")\n\n# create a new version of the scorer\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""integer"",  # <<- change type to integer\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\napi.save(spec1, ""temperature-scorer"")\n```', '<2-hop>\n\nOpen the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\n5. Make an annotation. 6. Click Save. 7. In the call details page, click Feedback to view the calls table. The new annotation displays in the table. You can also view the annotations in the Annotations column in the call table in Traces.\n\nRefresh the call table to view the most up-to-date information.\n\nCreate a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.']","To make and update a human annotation scorer using the API, you first create a new version of the scorer by using the original object ID on save, as shown in the example with the Temperature scorer. You use the AnnotationSpec class to define the scorer's properties, such as name, description, and field schema. After saving the scorer with the API, you can view the history of all versions in the Scorers tab under Human annotations. To see changes, open the call details page, click the Show feedback button to display available human annotation scorers in the sidebar, make an annotation, and click Save. The new annotation will display in the calls table and the Annotations column in the call table in Traces.",multi_hop_specific_query_synthesizer
How can Python be used to manage costs and object references in Weave projects?,"['<1-hop>\n\n```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nPurging a custom cost\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")\n\ncosts = client.query_costs(llm_ids=[""your_model_name""])\nclient.purge_costs([cost.id for cost in costs])\n```\n\nCalculating costs for a Project\n\n```python\nimport weave\n\nweave.init(""project_costs"")\n@weave.op()\ndef get_costs_for_project(project_name: str):\n    total_cost = 0\n    requests = 0\n\n    client = weave.init(project_name)\n    # Fetch all the calls in the project\n    calls = list(\n        client.get_calls(filter={""trace_roots_only"": True}, include_costs=True)\n    )', '<2-hop>\n\nGetting an object back\n\nYou can construct a ref and then fetch the object back.\n\n```python\nweave.init(\'intro-example\')\ncat_names = weave.ref(\'cat-names\').get()\n```\n\nDeleting an object\n\n```python\nweave.init(\'intro-example\')\ncat_names_ref = weave.ref(\'cat-names:v1\')\ncat_names_ref.delete()\n```\n\nTrying to access a deleted object will result in an error. Resolving an object that has a reference to a deleted object will return a `DeletedRef` object in place of the deleted object.\n\nRef styles\n\nA fully qualified weave object ref uri looks like this:\n\nweave:///<entity>/<project>/object/<object_name>:<object_version>\n\nentity: wandb entity (username or team)\n\nproject: wandb project\n\nobject_name: object name\n\nobject_version: either a version hash, a string like v0, v1..., or an alias like "":latest"". All objects have the "":latest"" alias.\n\nRefs can be constructed with a few different styles\n\nweave.ref(<name>): requires weave.init(<project>) to have been called. Refers to the "":latest"" version']","Python can be used to manage costs in Weave projects by initializing a client with `weave.init()` and querying or purging costs using methods like `client.query_costs()` and `client.purge_costs()`. For managing object references, Python allows constructing references with `weave.ref()` after initializing a project with `weave.init()`. Objects can be fetched or deleted using these references, and attempting to access a deleted object will result in a `DeletedRef` object.",multi_hop_specific_query_synthesizer
How can a UUID be utilized to delete feedback from a call and what role do human annotations play in this process?,"['<1-hop>\n\nDuring call execution\n\nAfter call execution\n\nDuring call execution\n\nTo retrieve the UUID during call execution, get the current call, and return the ID.\n\nimport weave\nweave.init(""uuid"")\n\n@weave.op()\ndef simple_operation(input_value):\n    # Perform some simple operation\n    output = f""Processed {input_value}""\n    # Get the current call ID\n    current_call = weave.require_current_call()\n    call_id = current_call.id\n    return output, call_id\n```\n\nAfter call execution\n\nAlternatively, you can use call() method to execute the operation and retrieve the ID after call execution:\n\n@weave.op()\ndef simple_operation(input_value):\n    return f""Processed {input_value}""\n\n# Execute the operation and retrieve the result and call ID\nresult, call = simple_operation.call(""example input"")\ncall_id = call.id\n```\n\nDelete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations', '<2-hop>\n\nDelete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations\n\nHuman annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the UI or the API. Then, you can use the scorer in the UI to make annotations, and modify your annotation scorers using the API.\n\nCreate a human annotation scorer in the UI\n\nTo create a human annotation scorer in the UI, do the following:\n\nIn the sidebar, navigate to Scorers.\n\nIn the upper right corner, click + Create scorer.\n\nIn the configuration page, set:\n\nScorer type to Human annotation\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.']","A UUID can be utilized to delete feedback from a call by specifying it as the identifier for the particular call whose feedback needs to be removed. Human annotations play a role in this process by allowing users to create and manage annotation scorers in the Weave UI, which can be used to provide additional insights and feedback on call interactions. These annotations can be configured to collect various types of feedback, such as boolean or integer, enhancing the overall analysis and management of call data.",multi_hop_specific_query_synthesizer
"How can a software developer use the API to create and modify human annotation scorers, such as the Temperature scorer, and what are the implications of these modifications on the scorer's version history?","['<1-hop>\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.\n\nIn the following example, two scorers are created. The first scorer, Temperature, is used to score the perceived temperature of the LLM call. The second scorer, Tone, is used to score the tone of the LLM response. Each scorer is created using save with an associated object ID (temperature-scorer and tone-scorer).\n\napi = weave.init(""feedback-example"")\n\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""number"",\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\nspec2 = AnnotationSpec(\n  name=""Tone"",\n  description=""The tone of the llm response"",\n  field_schema={\n    ""type"": ""string"",\n    ""enum"": [""Aggressive"", ""Neutral"", ""Polite"", ""N/A""],\n  },\n)\napi.save(spec1, ""temperature-scorer"")\napi.save(spec2, ""tone-scorer"")\n```\n\nModify a human annotation scorer using the API', '<2-hop>\n\nModify a human annotation scorer using the API\n\nExpanding on creating a human annotation scorer using the API, the following example creates an updated version of the Temperature scorer, by using the original object ID (temperature-scorer) on save. The result is an updated object, with a history of all versions.\n\nYou can view human annotation scorer object history in the Scorers tab under Human annotations.\n\napi = weave.init(""feedback-example"")\n\n# create a new version of the scorer\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""integer"",  # <<- change type to integer\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\napi.save(spec1, ""temperature-scorer"")\n```']","A software developer can use the API to create human annotation scorers by importing the AnnotationSpec class and using the save method on the weave client. For example, the Temperature scorer is created to score the perceived temperature of an LLM call with a field schema specifying a number type. To modify this scorer, the developer can update the field schema, such as changing the type to integer, and save it using the original object ID (temperature-scorer). This action results in an updated object with a history of all versions, which can be viewed in the Scorers tab under Human annotations. These modifications allow for tracking changes and maintaining a version history of the scorer.",multi_hop_specific_query_synthesizer
How do you disable system and client information capture in Weave and what is the impact on Op execution speed?,"[""<1-hop>\n\nCode capture - Weave captures a representation of the Op's source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged."", '<2-hop>\n\nHow can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_system_info"": False}).\n\nHow can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_client_info"": False}).\n\nWill Weave affect my function\'s execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM. To minimize Weave\'s impact on the speed of your Op\'s execution, its network activity happens on a background thread. When your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\nHow is Weave data ingestion calculated?']","To disable system information capture in Weave, you can initialize the Weave client with the following command: weave.init(""entity/project"", settings={""capture_system_info"": False}). Similarly, to disable client information capture, use: weave.init(""entity/project"", settings={""capture_client_info"": False}). The impact of Weave on Op execution speed is typically negligible compared to making a call to an LLM, as Weave's network activity occurs on a background thread. However, when your program is exiting, it may appear to pause while any remaining enqueued data is logged.",multi_hop_specific_query_synthesizer
"How can TypeScript be used with Weave ops, and what limitations currently exist for cost management in TypeScript?","[""<1-hop>\n\nimport Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init('intro-example')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don't call `weave.init('your-project-name')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from 'weave'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)"", '<2-hop>\n\nimport Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nCosts\n\nAdding a custom cost\n\n```python\nimport weave\nfrom datetime import datetime\n\nclient = weave.init(""my_custom_cost_model"")\n\nclient.add_cost(\n    llm_id=""your_model_name"",\n    prompt_token_cost=0.01,\n    completion_token_cost=0.02\n)\n\nclient.add_costs(\n    llm_id=""your_model_name"",\n    prompt_token_cost=10,\n    completion_token_cost=20,\n    # If for example I want to raise the price of the model after a certain date\n    effective_date=datetime(2025, 4, 22),\n)\n```\n\n```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nQuerying for costs\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")\n\ncosts = client.query_costs(llm_ids=[""your_model_name""])\n\ncost = client.query_costs(costs[0].id)\n```\n\n```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nPurging a custom cost\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")']","TypeScript can be used with Weave ops by importing the Weave library and defining functions that can be tracked. For example, a function `trackMe` can be defined and then wrapped with `weave.op` to create a trackable operation. However, there are limitations in TypeScript regarding cost management features. Specifically, the ability to add and query custom costs, which is available in Python, is not yet available in TypeScript.",multi_hop_specific_query_synthesizer
"How can the AnnotationSpec class be used to create and modify human annotation scorers for analyzing call interactions, and how are these annotations displayed in the call details page?","['<1-hop>\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.\n\nIn the following example, two scorers are created. The first scorer, Temperature, is used to score the perceived temperature of the LLM call. The second scorer, Tone, is used to score the tone of the LLM response. Each scorer is created using save with an associated object ID (temperature-scorer and tone-scorer).\n\napi = weave.init(""feedback-example"")\n\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""number"",\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\nspec2 = AnnotationSpec(\n  name=""Tone"",\n  description=""The tone of the llm response"",\n  field_schema={\n    ""type"": ""string"",\n    ""enum"": [""Aggressive"", ""Neutral"", ""Polite"", ""N/A""],\n  },\n)\napi.save(spec1, ""temperature-scorer"")\napi.save(spec2, ""tone-scorer"")\n```\n\nModify a human annotation scorer using the API', '<2-hop>\n\nOpen the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\n5. Make an annotation. 6. Click Save. 7. In the call details page, click Feedback to view the calls table. The new annotation displays in the table. You can also view the annotations in the Annotations column in the call table in Traces.\n\nRefresh the call table to view the most up-to-date information.\n\nCreate a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.']","The AnnotationSpec class, imported from weave.flow.annotation_spec, is used to create human annotation scorers by defining specific attributes such as name, description, and field schema. For example, a scorer named 'Temperature' can be created to assess the perceived temperature of an LLM call, and another named 'Tone' to evaluate the tone of the LLM response. These scorers are saved using the save method on the weave client with unique object IDs. Once created, these scorers can be modified using the API. In the call details page, users can click the Show feedback button to display available human annotation scorers in the sidebar. Annotations can be made and saved, and they will appear in the calls table under the Feedback section. The annotations are also visible in the Annotations column in the call table in Traces, and refreshing the call table ensures the most up-to-date information is displayed.",multi_hop_specific_query_synthesizer
how ops and op calls work with weave?,"[""<1-hop>\n\nimport Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init('intro-example')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don't call `weave.init('your-project-name')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from 'weave'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)"", '<2-hop>\n\nOp call hierarchy - When an Op is called within the context of another Op executing, this relationship is captured, even in cases where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a ""Trace tree"".\n\nExecution status and exceptions - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\nSystem information - Weave may capture information about which operating system the client is running on including detailed version information.\n\nClient information - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.']","Ops in Weave are versioned functions that automatically log all calls. When an Op is called, it creates a new version if the code has changed since the last call, logging the inputs and outputs. If an Op is called within another Op, this relationship is captured to provide a 'Trace tree'. Weave also tracks execution status, exceptions, system information, client information, timing, and token usage.",multi_hop_specific_query_synthesizer
"How can the Python SDK be used to redact PII from traces in Weights & Biases, and what are the implications of using object references in this context?","['<1-hop>\n\nGetting an object back\n\nYou can construct a ref and then fetch the object back.\n\n```python\nweave.init(\'intro-example\')\ncat_names = weave.ref(\'cat-names\').get()\n```\n\nDeleting an object\n\n```python\nweave.init(\'intro-example\')\ncat_names_ref = weave.ref(\'cat-names:v1\')\ncat_names_ref.delete()\n```\n\nTrying to access a deleted object will result in an error. Resolving an object that has a reference to a deleted object will return a `DeletedRef` object in place of the deleted object.\n\nRef styles\n\nA fully qualified weave object ref uri looks like this:\n\nweave:///<entity>/<project>/object/<object_name>:<object_version>\n\nentity: wandb entity (username or team)\n\nproject: wandb project\n\nobject_name: object name\n\nobject_version: either a version hash, a string like v0, v1..., or an alias like "":latest"". All objects have the "":latest"" alias.\n\nRefs can be constructed with a few different styles\n\nweave.ref(<name>): requires weave.init(<project>) to have been called. Refers to the "":latest"" version', '<2-hop>\n\nRedact PII from Traces\n\n:::important This feature is only available for Enterprise users, and is only accessible via the Python SDK. :::\n\nSome organizations process Personally Identifiable Information (PII) such as names, phone numbers, and email addresses in their Large Language Model (LLM) workflows. Storing this data in Weights & Biases (W&B) Weave poses compliance and security risks.\n\nThe Sensitive Data Protection feature allows you to automatically redact Personally Identifiable Information (PII) from a trace before it is sent to Weave servers. This feature integrates Microsoft Presidio into the Weave Python SDK, which means that you can control redaction settings at the SDK level.\n\nThe Sensitive Data Protection feature introduces the following functionality to the Python SDK:\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.']","The Python SDK can be used to redact Personally Identifiable Information (PII) from traces in Weights & Biases by utilizing the Sensitive Data Protection feature, which integrates Microsoft Presidio. This feature allows users to automatically redact PII by toggling the redact_pii setting on in the weave.init call. This ensures that sensitive information is not stored in Weave, mitigating compliance and security risks. In the context of using object references, the Python SDK allows for the construction and management of object references, such as fetching and deleting objects. A fully qualified weave object ref URI is used to manage these references, which can be crucial when handling sensitive data, as accessing a deleted object will result in a `DeletedRef` object, ensuring that sensitive information is not inadvertently accessed.",multi_hop_specific_query_synthesizer
How does the integration of the SDK in Weave's feedback system enhance the process of monitoring and optimizing code performance through human annotations and feedback management?,"['<1-hop>\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nFrom the call details page\n\nIn the sidebar, navigate to Traces.\n\nFind the row for the call that you want to add feedback to.\n\nOpen the call details page.\n\nSelect the Feedback column for the call.\n\nAdd, view, or delete feedback:\n\nAdd and view feedback using the icons located in the upper right corner of the call details feedback view.\n\nView and delete feedback from the call details feedback table. Delete feedback by clicking the trashcan icon in the rightmost column of the appropriate feedback row.\n\nUse the icons\n\nYou can add or remove a reaction, and add a note using the icons that are located in both the call table and individual call details pages.\n\nCall table: Located in Feedback column in the appropriate row in the call table.\n\nCall details page: Located in the upper right corner of each call details page.', ""<2-hop>\n\nimport Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nFeedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\nBuild evaluation datasets for performance monitoring.\n\nIdentify and resolve LLM content issues effectively.\n\nGather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weaveâ€™s feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\nProvide feedback in the UI\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.""]","The integration of the SDK in Weave's feedback system enhances the process of monitoring and optimizing code performance by allowing users to provide call feedback directly through the UI or programmatically via the SDK. This system supports various feedback types, including emoji reactions, textual comments, and structured data, which are crucial for building evaluation datasets for performance monitoring. Additionally, it enables the identification and resolution of LLM content issues and the gathering of examples for advanced tasks like fine-tuning. Human annotations further contribute to detailed evaluations, making the feedback system robust and efficient for performance optimization.",multi_hop_specific_query_synthesizer
"Howw doo youu enablee andd customizee PII redactionn usingg Presidioo in Weavee, andd whatare the defaultt entitiess thatt gett redacted?","['<1-hop>\n\nFor a full list of the entities that can be detected and redacted, see PII entities supported by Presidio.\n\nEntities redacted by default\n\nThe following entities are automatically redacted when PII redaction is enabled:\n\nCREDIT_CARD\n\nCRYPTO\n\nEMAIL_ADDRESS\n\nES_NIF\n\nFI_PERSONAL_IDENTITY_CODE\n\nIBAN_CODE\n\nIN_AADHAAR\n\nIN_PAN\n\nIP_ADDRESS\n\nLOCATION\n\nPERSON\n\nPHONE_NUMBER\n\nUK_NHS\n\nUK_NINO\n\nUS_BANK_NUMBER\n\nUS_DRIVER_LICENSE\n\nUS_PASSPORT\n\nUS_SSN\n\nUsage information\n\nThis feature is only available in the Python SDK.\n\nEnabling redaction increases processing time due to the Presidio dependency.', '<2-hop>\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.\n\nCustomizable redaction fields using the configurable redact_pii_fields setting.\n\nEnable PII redaction\n\nTo get started with the Sensitive Data Protection feature in Weave, complete the following steps:\n\nInstall the required dependencies:\n\nbash pip install presidio-analyzer presidio-anonymizer\n\nModify your weave.init call to enable redaction. When redact_pii=True, common entities are redacted by default:\n\n```python import weave\n\nweave.init(""my-project"", settings={""redact_pii"": True}) ```\n\n(Optional) Customize redaction fields using the redact_pii_fields parameter:\n\npython weave.init(""my-project"", settings={""redact_pii"": True, ""redact_pii_fields""=[""CREDIT_CARD"", ""US_SSN""]})\n\nFor a full list of the entities that can be detected and redacted, see PII entities supported by Presidio.\n\nEntities redacted by default']","To enable and customize PII redaction using Presidio in Weave, you need to install the required dependencies by running the command `pip install presidio-analyzer presidio-anonymizer`. Then, modify your `weave.init` call to enable redaction by setting `redact_pii=True`, which will automatically redact common entities by default. You can further customize the redaction fields using the `redact_pii_fields` parameter, for example: `weave.init(""my-project"", settings={""redact_pii"": True, ""redact_pii_fields"":[""CREDIT_CARD"", ""US_SSN""]})`. The default entities that get redacted when PII redaction is enabled include CREDIT_CARD, CRYPTO, EMAIL_ADDRESS, ES_NIF, FI_PERSONAL_IDENTITY_CODE, IBAN_CODE, IN_AADHAAR, IN_PAN, IP_ADDRESS, LOCATION, PERSON, PHONE_NUMBER, UK_NHS, UK_NINO, US_BANK_NUMBER, US_DRIVER_LICENSE, US_PASSPORT, and US_SSN.",multi_hop_specific_query_synthesizer
What is the role of Tabs in the provided code context?,"['import Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nCosts\n\nAdding a custom cost\n\n```python\nimport weave\nfrom datetime import datetime\n\nclient = weave.init(""my_custom_cost_model"")\n\nclient.add_cost(\n    llm_id=""your_model_name"",\n    prompt_token_cost=0.01,\n    completion_token_cost=0.02\n)\n\nclient.add_costs(\n    llm_id=""your_model_name"",\n    prompt_token_cost=10,\n    completion_token_cost=20,\n    # If for example I want to raise the price of the model after a certain date\n    effective_date=datetime(2025, 4, 22),\n)\n```\n\n```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nQuerying for costs\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")\n\ncosts = client.query_costs(llm_ids=[""your_model_name""])\n\ncost = client.query_costs(costs[0].id)\n```\n\n```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nPurging a custom cost\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")']","In the provided code context, Tabs is imported from '@theme/Tabs', indicating its use as a component or module related to theming, likely for organizing or displaying content in a tabbed interface.",single_hop_specifc_query_synthesizer
Is the feature currently available in TypeScript?,"['```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nPurging a custom cost\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")\n\ncosts = client.query_costs(llm_ids=[""your_model_name""])\nclient.purge_costs([cost.id for cost in costs])\n```\n\nCalculating costs for a Project\n\n```python\nimport weave\n\nweave.init(""project_costs"")\n@weave.op()\ndef get_costs_for_project(project_name: str):\n    total_cost = 0\n    requests = 0\n\n    client = weave.init(project_name)\n    # Fetch all the calls in the project\n    calls = list(\n        client.get_calls(filter={""trace_roots_only"": True}, include_costs=True)\n    )']",This feature is not available in TypeScript yet. Stay tuned!,single_hop_specifc_query_synthesizer
How is Python used in the context of Weave ops?,"[""import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init('intro-example')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don't call `weave.init('your-project-name')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from 'weave'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)""]","In the context of Weave ops, Python is used to define functions that are decorated with `@weave.op()`, which automatically logs all calls and creates a new op version if the code changes. The example provided shows a Python function `track_me` that adds 5 to its input and is tracked using Weave.",single_hop_specifc_query_synthesizer
Waht is Weave?,"[""```python\n@weave.op(tracing_sample_rate=0.1)  # Only trace ~10% of calls\ndef high_frequency_op(x: int) -> int:\n    return x + 1\n\n@weave.op(tracing_sample_rate=1.0)  # Always trace (default)\ndef always_traced_op(x: int) -> int:\n    return x + 1\n```\n\nWhen an op's call is not sampled:\n- The function executes normally\n- No trace data is sent to Weave\n- Child ops are also not traced for that call\n\nThe sampling rate must be between 0.0 and 1.0 inclusive.\n\nControl call link output\n\nIf you want to suppress the printing of call links during logging, you can set the WEAVE_PRINT_CALL_LINK environment variable to false. This can be useful if you want to reduce output verbosity and reduce clutter in your logs.\n\nbash export WEAVE_PRINT_CALL_LINK=false\n\nDeleting an op\n\n```python\nweave.init('intro-example')\nmy_op_ref = weave.ref('track_me:v1')\nmy_op_ref.delete()\n```\n\nTrying to access a deleted op will result in an error.""]","Weave is a system used for tracing operations, where you can control the sampling rate of call traces and manage call link outputs.",single_hop_specifc_query_synthesizer
Could you elaborate on how Weave captures information for a function and the level of control it offers over the logging process?,"['FAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.']","A function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default.",single_hop_specifc_query_synthesizer
What Weave do with code capture and how it help with Op versioning?,"[""Code capture - Weave captures a representation of the Op's source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.""]","Weave captures a representation of the Op's source code, including inline comments and the value of variables or the source of non-Op functions that were called. This allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time.",single_hop_specifc_query_synthesizer
What Trace tree do?,"['Op call hierarchy - When an Op is called within the context of another Op executing, this relationship is captured, even in cases where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a ""Trace tree"".\n\nExecution status and exceptions - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\nSystem information - Weave may capture information about which operating system the client is running on including detailed version information.\n\nClient information - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.']","The Trace tree provides a relationship between Op calls, capturing when an Op is called within the context of another Op executing, even if there is an intermediate non-Op function executing.",single_hop_specifc_query_synthesizer
What Weave do with info it logs?,"['Timing - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.\n\nUser and run context - Logging is associated with a W&B user account. That will be captured along with any wandb Run context.\n\nDerived information - Weave may compute derived information from the raw information logged, for example a cost estimate may be calculated based on token usage and knowledge of the model used. Weave also aggregates some information over calls.\n\nAdditional information you choose - You can choose to log custom attributes as part of your call or attach feedback to a call.\n\nHow can I disable code capture?\n\nYou can disable code capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_code"": False}). You can also use the environment variable WEAVE_CAPTURE_CODE=false.\n\nHow can I disable system information capture?']","Weave may compute derived information from the raw information logged, such as calculating a cost estimate based on token usage and knowledge of the model used. It also aggregates some information over calls.",single_hop_specifc_query_synthesizer
LLM slow down calls?,"['How can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_system_info"": False}).\n\nHow can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_client_info"": False}).\n\nWill Weave affect my function\'s execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM. To minimize Weave\'s impact on the speed of your Op\'s execution, its network activity happens on a background thread. When your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\nHow is Weave data ingestion calculated?']",The overhead of Weave logging is typically negligible compared to making a call to an LLM.,single_hop_specifc_query_synthesizer
How does Weave calculate data ingestion?,"['How is Weave data ingestion calculated?\n\nWe define ingested bytes as bytes that we receive, process, and store on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information you explicitly log to Weave, but does not include communication overhead (e.g., HTTP headers) or any other data that is not placed in long-term storage. We count bytes as ""ingested"" only once at the time they are received and stored.']","Weave calculates data ingestion by counting the bytes that are received, processed, and stored on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information explicitly logged to Weave. It does not include communication overhead or data not placed in long-term storage. Bytes are counted as 'ingested' only once at the time they are received and stored.",single_hop_specifc_query_synthesizer
Wht is the use of Tabs in the code?,"[""import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nObjects\n\nPublishing an object\n\nWeave's serialization layer saves and versions objects.\n\n```python\nimport weave\n# Initialize tracking to the project 'intro-example'\nweave.init('intro-example')\n# Save a list, giving it the name 'cat-names'\nweave.publish(['felix', 'jimbo', 'billie'], 'cat-names')\n```\n\n```typescript\nimport * as weave from 'weave'\n\n// Initialize tracking to the project 'intro-example'\nconst client = await weave.init('intro-example')\n\n// Save an array, giving it the name 'cat-names'\nclient.publish(['felix', 'jimbo', 'billie'], 'cat-names')\n```\n\nSaving an object with a name will create the first version of that object if it doesn't exist.\n\nGetting an object back\n\nYou can construct a ref and then fetch the object back.\n\n```python\nweave.init('intro-example')\ncat_names = weave.ref('cat-names').get()\n```\n\nDeleting an object""]",Tabs are imported from '@theme/Tabs' and are likely used for organizing or displaying content in a tabbed interface.,single_hop_specifc_query_synthesizer
What does a fully qualified weave object ref URI look like?,"['Getting an object back\n\nYou can construct a ref and then fetch the object back.\n\n```python\nweave.init(\'intro-example\')\ncat_names = weave.ref(\'cat-names\').get()\n```\n\nDeleting an object\n\n```python\nweave.init(\'intro-example\')\ncat_names_ref = weave.ref(\'cat-names:v1\')\ncat_names_ref.delete()\n```\n\nTrying to access a deleted object will result in an error. Resolving an object that has a reference to a deleted object will return a `DeletedRef` object in place of the deleted object.\n\nRef styles\n\nA fully qualified weave object ref uri looks like this:\n\nweave:///<entity>/<project>/object/<object_name>:<object_version>\n\nentity: wandb entity (username or team)\n\nproject: wandb project\n\nobject_name: object name\n\nobject_version: either a version hash, a string like v0, v1..., or an alias like "":latest"". All objects have the "":latest"" alias.\n\nRefs can be constructed with a few different styles\n\nweave.ref(<name>): requires weave.init(<project>) to have been called. Refers to the "":latest"" version']","A fully qualified weave object ref URI looks like this: weave:///<entity>/<project>/object/<object_name>:<object_version>. The entity is a wandb entity (username or team), the project is a wandb project, the object_name is the name of the object, and the object_version can be a version hash, a string like v0, v1..., or an alias like "":latest"".",single_hop_specifc_query_synthesizer
What are the tracing capabilities of Weave in AI-powered applications?,"['Tracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:']","Weave provides powerful tracing capabilities to track and version objects and function calls in AI-powered applications. This system enables better monitoring, debugging, and iterative development by allowing users to track insights between commits.",single_hop_specifc_query_synthesizer
Wht is the purpse of Weave's objcts?,"[""Objects\n\nObjects form Weave's extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application's behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page""]","Objects form Weave's extensible serialization layer, automatically versioning runtime objects, which allows you to track changes in data structures over time, maintain a clear history of object modifications, and easily revert to previous versions when needed.",single_hop_specifc_query_synthesizer
Wht is LLM?,"[""import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nFeedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\nBuild evaluation datasets for performance monitoring.\n\nIdentify and resolve LLM content issues effectively.\n\nGather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weaveâ€™s feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\nProvide feedback in the UI\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.""]","LLM applications require robust tooling to collect and analyze feedback, which Weave provides through an integrated feedback system.",single_hop_specifc_query_synthesizer
