user_input,retrieved_contexts,response,reference,context_recall,factual_correctness,faithfulness,llm_context_precision_without_reference,noise_sensitivity_relevant,answer_relevancy,context_entity_recall
How does Weave manage the execution speed of Op calls while capturing detailed system and client information?,"['FAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nOp call hierarchy - When an Op is called within the context of another Op executing, this relationship is captured, even in cases where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a ""Trace tree"".\n\nExecution status and exceptions - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\nSystem information - Weave may capture information about which operating system the client is running on including detailed version information.\n\nClient information - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.\n\nHow can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_system_info"": False}).\n\nHow can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_client_info"": False}).\n\nWill Weave affect my function\'s execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM. To minimize Weave\'s impact on the speed of your Op\'s execution, its network activity happens on a background thread. When your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\nHow is Weave data ingestion calculated?\n\nCode capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.']","Weave manages the execution speed of Op calls by ensuring that the overhead of logging is negligible compared to the actual LLM calls, and it offloads network activity to a background thread. This design minimizes the impact on execution speed while capturing detailed information about the Op calls, including execution status, timing, and client/system info. By logging these details effectively, Weave provides insights without significant delays in function execution.","Weave manages the execution speed of Op calls by ensuring that its network activity occurs on a background thread, which minimizes its impact on the speed of the Op's execution. This is important because Weave captures detailed system and client information, such as the operating system details and the programming language in use. Despite this data capture, the overhead of Weave logging is typically negligible compared to making a call to an LLM. However, when the program is exiting, it may pause while any remaining enqueued data is logged.",1.0,0.57,1.0,0.9999999999,0.4,0.9532561085186235,0.9999999966666667
"How does the Weave Python SDK facilitate the redaction of Personally Identifiable Information (PII) in enterprise environments, and what role does the Python SDK play in the versioning and tracking of Weave operations?","['Redact PII from Traces\n\n:::important This feature is only available for Enterprise users, and is only accessible via the Python SDK. :::\n\nSome organizations process Personally Identifiable Information (PII) such as names, phone numbers, and email addresses in their Large Language Model (LLM) workflows. Storing this data in Weights & Biases (W&B) Weave poses compliance and security risks.\n\nThe Sensitive Data Protection feature allows you to automatically redact Personally Identifiable Information (PII) from a trace before it is sent to Weave servers. This feature integrates Microsoft Presidio into the Weave Python SDK, which means that you can control redaction settings at the SDK level.\n\nThe Sensitive Data Protection feature introduces the following functionality to the Python SDK:\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.\n\nCustomizable redaction fields using the configurable redact_pii_fields setting.\n\nEnable PII redaction\n\nTo get started with the Sensitive Data Protection feature in Weave, complete the following steps:\n\nInstall the required dependencies:\n\nbash pip install presidio-analyzer presidio-anonymizer\n\nModify your weave.init call to enable redaction. When redact_pii=True, common entities are redacted by default:\n\n```python import weave\n\nweave.init(""my-project"", settings={""redact_pii"": True}) ```\n\n(Optional) Customize redaction fields using the redact_pii_fields parameter:\n\npython weave.init(""my-project"", settings={""redact_pii"": True, ""redact_pii_fields""=[""CREDIT_CARD"", ""US_SSN""]})\n\nFor a full list of the entities that can be detected and redacted, see PII entities supported by Presidio.\n\nEntities redacted by default\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:']","The Weave Python SDK facilitates the redaction of Personally Identifiable Information (PII) by integrating Microsoft Presidio, allowing users to automatically redact sensitive data before it reaches Weave servers. Users can control redaction settings through the SDK, including toggling PII redaction on or off and customizing redaction fields. Additionally, the SDK enables versioning and tracking of Weave operations, allowing for monitoring of changes in data structures and experimentation reproducibility.","The Weave Python SDK facilitates the redaction of Personally Identifiable Information (PII) in enterprise environments by integrating Microsoft Presidio, which allows users to control redaction settings at the SDK level. This is achieved through the Sensitive Data Protection feature, which introduces a redact_pii setting that can be toggled on or off in the weave.init call to enable automatic redaction of common entities. Additionally, the Python SDK plays a crucial role in the versioning and tracking of Weave operations by allowing functions decorated with @weave.op() to automatically log all calls and create new op versions if the code changes from the last call. This ensures that inputs and outputs of the function are logged, providing a comprehensive tracking mechanism.",0.5,0.52,0.625,0.9999999999,0.25,0.8977935830963376,0.49999999964285713
How does Weave utilize code capture and Op call hierarchy to improve the evaluation of language models?,"['Code capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nOp call hierarchy - When an Op is called within the context of another Op executing, this relationship is captured, even in cases where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a ""Trace tree"".\n\nExecution status and exceptions - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\nSystem information - Weave may capture information about which operating system the client is running on including detailed version information.\n\nClient information - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.']","Weave improves the evaluation of language models by capturing detailed information about function calls and their execution context through code capture and Op call hierarchy. Code capture provides insights into the Op's source code and variable states, aiding in understanding function behavior over time. The Op call hierarchy establishes relationships between function calls, enabling the creation of a ""Trace tree"" that enhances monitoring and debugging processes.","Weave utilizes code capture by recording a representation of the Op's source code, including inline comments and the values of variables or sources of non-Op functions called. This allows for understanding the evaluation of code over time, even if changes are not saved to the source control system. Additionally, the Op call hierarchy is captured, which records the relationship between Op calls, even when intermediate non-Op functions are executed. This information is used to provide a 'Trace tree,' which helps in evaluating and improving the performance of language models by offering insights into the execution flow and dependencies.",0.75,0.6,0.6666666666666666,0.9999999999,0.0,0.9122986094767565,0.7499999981250001
How can you create a human annotation scorer using the API and UI in Weave?,"['Open the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\n5. Make an annotation. 6. Click Save. 7. In the call details page, click Feedback to view the calls table. The new annotation displays in the table. You can also view the annotations in the Annotations column in the call table in Traces.\n\nRefresh the call table to view the most up-to-date information.\n\nCreate a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.\n\nDelete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations\n\nHuman annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the UI or the API. Then, you can use the scorer in the UI to make annotations, and modify your annotation scorers using the API.\n\nCreate a human annotation scorer in the UI\n\nTo create a human annotation scorer in the UI, do the following:\n\nIn the sidebar, navigate to Scorers.\n\nIn the upper right corner, click + Create scorer.\n\nIn the configuration page, set:\n\nScorer type to Human annotation\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.\n\nModify a human annotation scorer using the API\n\nExpanding on creating a human annotation scorer using the API, the following example creates an updated version of the Temperature scorer, by using the original object ID (temperature-scorer) on save. The result is an updated object, with a history of all versions.\n\nYou can view human annotation scorer object history in the Scorers tab under Human annotations.\n\napi = weave.init(""feedback-example"")\n\n# create a new version of the scorer\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""integer"",  # <<- change type to integer\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\napi.save(spec1, ""temperature-scorer"")\n```\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.\n\nIn the following example, two scorers are created. The first scorer, Temperature, is used to score the perceived temperature of the LLM call. The second scorer, Tone, is used to score the tone of the LLM response. Each scorer is created using save with an associated object ID (temperature-scorer and tone-scorer).\n\napi = weave.init(""feedback-example"")\n\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""number"",\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\nspec2 = AnnotationSpec(\n  name=""Tone"",\n  description=""The tone of the llm response"",\n  field_schema={\n    ""type"": ""string"",\n    ""enum"": [""Aggressive"", ""Neutral"", ""Polite"", ""N/A""],\n  },\n)\napi.save(spec1, ""temperature-scorer"")\napi.save(spec2, ""tone-scorer"")\n```\n\nModify a human annotation scorer using the API']","To create a human annotation scorer using the Weave UI, navigate to the Scorers section in the sidebar, click ""+ Create scorer,"" and set the scorer type to ""Human annotation"" along with its name and description. For API integration, import the AnnotationSpec class, define the scorer's specifications, and use the save method to create it programmatically. After creation, you can use this scorer to make and manage annotations.","To create a human annotation scorer using the API in Weave, you need to import the AnnotationSpec class from weave.flow.annotation_spec and use the save method on the weave client to create the scorer. Each scorer is its own object, created and updated independently. Alternatively, to create a human annotation scorer in the UI, navigate to Scorers in the sidebar, click + Create scorer in the upper right corner, and set the configuration page with the scorer type as Human annotation, along with a name, description, and type of feedback to be collected. Then, click Create scorer to finalize the process.",1.0,0.57,0.8888888888888888,0.9999999999,0.2222222222222222,0.9814242290805647,0.2857142853061225
How you make and update human annotation scorer using API and where you see changes?,"['Open the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\n5. Make an annotation. 6. Click Save. 7. In the call details page, click Feedback to view the calls table. The new annotation displays in the table. You can also view the annotations in the Annotations column in the call table in Traces.\n\nRefresh the call table to view the most up-to-date information.\n\nCreate a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.\n\nModify a human annotation scorer using the API\n\nExpanding on creating a human annotation scorer using the API, the following example creates an updated version of the Temperature scorer, by using the original object ID (temperature-scorer) on save. The result is an updated object, with a history of all versions.\n\nYou can view human annotation scorer object history in the Scorers tab under Human annotations.\n\napi = weave.init(""feedback-example"")\n\n# create a new version of the scorer\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""integer"",  # <<- change type to integer\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\napi.save(spec1, ""temperature-scorer"")\n```\n\nDelete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations\n\nHuman annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the UI or the API. Then, you can use the scorer in the UI to make annotations, and modify your annotation scorers using the API.\n\nCreate a human annotation scorer in the UI\n\nTo create a human annotation scorer in the UI, do the following:\n\nIn the sidebar, navigate to Scorers.\n\nIn the upper right corner, click + Create scorer.\n\nIn the configuration page, set:\n\nScorer type to Human annotation\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.\n\nIn the following example, a human annotator is asked to select which type of document the LLM ingested. As such, the Type selected for the score configuration is an enum containing the possible document types.\n\nUse the human annotation scorer in the UI\n\nOnce you create a human annotation scorer, it will automatically display in the Feedback sidebar of the call details page with the configured options. To use the scorer, do the following:\n\nIn the sidebar, navigate to Traces\n\nFind the row for the call that you want to add a human annotation to.\n\nOpen the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.']","To create and update a human annotation scorer using the API, import the AnnotationSpec class, then use the save method to create or update the scorer by referencing its object ID. Changes can be viewed in the Scorers tab under Human annotations, where you can see the object's history and versions. For immediate updates, refresh the call table to view the latest annotations.","To make and update a human annotation scorer using the API, you first create a new version of the scorer by using the original object ID on save, as shown in the example with the Temperature scorer. You use the AnnotationSpec class to define the scorer's properties, such as name, description, and field schema. After saving the scorer with the API, you can view the history of all versions in the Scorers tab under Human annotations. To see changes, open the call details page, click the Show feedback button to display available human annotation scorers in the sidebar, make an annotation, and click Save. The new annotation will display in the calls table and the Annotations column in the call table in Traces.",1.0,0.4,1.0,0.9999999999,0.4,0.9499701056780122,0.9999999987499999
How can Python be used to manage costs and object references in Weave projects?,"['Objects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\n```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nPurging a custom cost\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")\n\ncosts = client.query_costs(llm_ids=[""your_model_name""])\nclient.purge_costs([cost.id for cost in costs])\n```\n\nCalculating costs for a Project\n\n```python\nimport weave\n\nweave.init(""project_costs"")\n@weave.op()\ndef get_costs_for_project(project_name: str):\n    total_cost = 0\n    requests = 0\n\n    client = weave.init(project_name)\n    # Fetch all the calls in the project\n    calls = list(\n        client.get_calls(filter={""trace_roots_only"": True}, include_costs=True)\n    )\n\nimport Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nCosts\n\nAdding a custom cost\n\n```python\nimport weave\nfrom datetime import datetime\n\nclient = weave.init(""my_custom_cost_model"")\n\nclient.add_cost(\n    llm_id=""your_model_name"",\n    prompt_token_cost=0.01,\n    completion_token_cost=0.02\n)\n\nclient.add_costs(\n    llm_id=""your_model_name"",\n    prompt_token_cost=10,\n    completion_token_cost=20,\n    # If for example I want to raise the price of the model after a certain date\n    effective_date=datetime(2025, 4, 22),\n)\n```\n\n```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nQuerying for costs\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")\n\ncosts = client.query_costs(llm_ids=[""your_model_name""])\n\ncost = client.query_costs(costs[0].id)\n```\n\n```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nPurging a custom cost\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")']","Python can manage costs and object references in Weave projects by leveraging Weave's tracing capabilities to track and version objects and function calls. You can add, query, and purge costs associated with LLM (language model) usage through specific API calls, enabling streamlined cost management. This allows you to maintain clear records and optimize costs while providing insights into your application's performance.","Python can be used to manage costs in Weave projects by initializing a client with `weave.init()` and querying or purging costs using methods like `client.query_costs()` and `client.purge_costs()`. For managing object references, Python allows constructing references with `weave.ref()` after initializing a project with `weave.init()`. Objects can be fetched or deleted using these references, and attempting to access a deleted object will result in a `DeletedRef` object.",0.3333333333333333,0.24,0.42857142857142855,0.9999999999,0.2222222222222222,0.9874830965930083,0.2857142853061225
How can a UUID be utilized to delete feedback from a call and what role do human annotations play in this process?,"['Delete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations\n\nHuman annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the UI or the API. Then, you can use the scorer in the UI to make annotations, and modify your annotation scorers using the API.\n\nCreate a human annotation scorer in the UI\n\nTo create a human annotation scorer in the UI, do the following:\n\nIn the sidebar, navigate to Scorers.\n\nIn the upper right corner, click + Create scorer.\n\nIn the configuration page, set:\n\nScorer type to Human annotation\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.\n\nDuring call execution\n\nAfter call execution\n\nDuring call execution\n\nTo retrieve the UUID during call execution, get the current call, and return the ID.\n\nimport weave\nweave.init(""uuid"")\n\n@weave.op()\ndef simple_operation(input_value):\n    # Perform some simple operation\n    output = f""Processed {input_value}""\n    # Get the current call ID\n    current_call = weave.require_current_call()\n    call_id = current_call.id\n    return output, call_id\n```\n\nAfter call execution\n\nAlternatively, you can use call() method to execute the operation and retrieve the ID after call execution:\n\n@weave.op()\ndef simple_operation(input_value):\n    return f""Processed {input_value}""\n\n# Execute the operation and retrieve the result and call ID\nresult, call = simple_operation.call(""example input"")\ncall_id = call.id\n```\n\nDelete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nFrom the call details page\n\nIn the sidebar, navigate to Traces.\n\nFind the row for the call that you want to add feedback to.\n\nOpen the call details page.\n\nSelect the Feedback column for the call.\n\nAdd, view, or delete feedback:\n\nAdd and view feedback using the icons located in the upper right corner of the call details feedback view.\n\nView and delete feedback from the call details feedback table. Delete feedback by clicking the trashcan icon in the rightmost column of the appropriate feedback row.\n\nUse the icons\n\nYou can add or remove a reaction, and add a note using the icons that are located in both the call table and individual call details pages.\n\nCall table: Located in Feedback column in the appropriate row in the call table.\n\nCall details page: Located in the upper right corner of each call details page.\n\nOpen the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\n5. Make an annotation. 6. Click Save. 7. In the call details page, click Feedback to view the calls table. The new annotation displays in the table. You can also view the annotations in the Annotations column in the call table in Traces.\n\nRefresh the call table to view the most up-to-date information.\n\nCreate a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.']","A UUID can be utilized to delete feedback from a specific call by specifying it within the delete operation. Human annotations play a role in providing additional context or insights associated with the feedback, enhancing the overall data quality and usability. Annotations can be created through both the UI and API, allowing for versatile integration into the feedback process.","A UUID can be utilized to delete feedback from a call by specifying it as the identifier for the particular call whose feedback needs to be removed. Human annotations play a role in this process by allowing users to create and manage annotation scorers in the Weave UI, which can be used to provide additional insights and feedback on call interactions. These annotations can be configured to collect various types of feedback, such as boolean or integer, enhancing the overall analysis and management of call data.",1.0,0.57,0.5,0.9999999999,0.16666666666666666,0.9964481814873398,0.999999995
"How can a software developer use the API to create and modify human annotation scorers, such as the Temperature scorer, and what are the implications of these modifications on the scorer's version history?","['Modify a human annotation scorer using the API\n\nExpanding on creating a human annotation scorer using the API, the following example creates an updated version of the Temperature scorer, by using the original object ID (temperature-scorer) on save. The result is an updated object, with a history of all versions.\n\nYou can view human annotation scorer object history in the Scorers tab under Human annotations.\n\napi = weave.init(""feedback-example"")\n\n# create a new version of the scorer\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""integer"",  # <<- change type to integer\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\napi.save(spec1, ""temperature-scorer"")\n```\n\nOpen the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\n5. Make an annotation. 6. Click Save. 7. In the call details page, click Feedback to view the calls table. The new annotation displays in the table. You can also view the annotations in the Annotations column in the call table in Traces.\n\nRefresh the call table to view the most up-to-date information.\n\nCreate a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.\n\nIn the following example, a human annotator is asked to select which type of document the LLM ingested. As such, the Type selected for the score configuration is an enum containing the possible document types.\n\nUse the human annotation scorer in the UI\n\nOnce you create a human annotation scorer, it will automatically display in the Feedback sidebar of the call details page with the configured options. To use the scorer, do the following:\n\nIn the sidebar, navigate to Traces\n\nFind the row for the call that you want to add a human annotation to.\n\nOpen the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\nDelete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations\n\nHuman annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the UI or the API. Then, you can use the scorer in the UI to make annotations, and modify your annotation scorers using the API.\n\nCreate a human annotation scorer in the UI\n\nTo create a human annotation scorer in the UI, do the following:\n\nIn the sidebar, navigate to Scorers.\n\nIn the upper right corner, click + Create scorer.\n\nIn the configuration page, set:\n\nScorer type to Human annotation\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.']",A software developer can create and modify a human annotation scorer like the Temperature scorer by using the API to save updated versions of the scorer's specifications with the original object ID. This process results in an updated object while retaining a version history of all modifications made to the scorer. The implications of these modifications are that users can view the entire history of changes to the scorer in the Scorers tab under Human annotations.,"A software developer can use the API to create human annotation scorers by importing the AnnotationSpec class and using the save method on the weave client. For example, the Temperature scorer is created to score the perceived temperature of an LLM call with a field schema specifying a number type. To modify this scorer, the developer can update the field schema, such as changing the type to integer, and save it using the original object ID (temperature-scorer). This action results in an updated object with a history of all versions, which can be viewed in the Scorers tab under Human annotations. These modifications allow for tracking changes and maintaining a version history of the scorer.",1.0,0.63,0.8,0.9999999999,0.2,0.9571887248752035,0.5384615380473372
How do you disable system and client information capture in Weave and what is the impact on Op execution speed?,"['How can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_system_info"": False}).\n\nHow can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_client_info"": False}).\n\nWill Weave affect my function\'s execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM. To minimize Weave\'s impact on the speed of your Op\'s execution, its network activity happens on a background thread. When your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\nHow is Weave data ingestion calculated?\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.\n\nUser and run context - Logging is associated with a W&B user account. That will be captured along with any wandb Run context.\n\nDerived information - Weave may compute derived information from the raw information logged, for example a cost estimate may be calculated based on token usage and knowledge of the model used. Weave also aggregates some information over calls.\n\nAdditional information you choose - You can choose to log custom attributes as part of your call or attach feedback to a call.\n\nHow can I disable code capture?\n\nYou can disable code capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_code"": False}). You can also use the environment variable WEAVE_CAPTURE_CODE=false.\n\nHow can I disable system information capture?\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nCode capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.']","To disable system information capture in Weave, initialize the client with `weave.init(""entity/project"", settings={""capture_system_info"": False})`. To disable client information capture, use `weave.init(""entity/project"", settings={""capture_client_info"": False})`. Disabling these captures has a negligible impact on the execution speed of your operations, as logging occurs in a background thread.","To disable system information capture in Weave, you can initialize the Weave client with the following command: weave.init(""entity/project"", settings={""capture_system_info"": False}). Similarly, to disable client information capture, use: weave.init(""entity/project"", settings={""capture_client_info"": False}). The impact of Weave on Op execution speed is typically negligible compared to making a call to an LLM, as Weave's network activity occurs on a background thread. However, when your program is exiting, it may appear to pause while any remaining enqueued data is logged.",1.0,0.44,0.75,0.9999999999,0.25,0.9502503076760273,0.9999999966666667
"How can TypeScript be used with Weave ops, and what limitations currently exist for cost management in TypeScript?","['FAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nimport Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init(\'intro-example\')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don\'t call `weave.init(\'your-project-name\')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from \'weave\'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)\n\nCode capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.']","TypeScript can be used with Weave ops by defining a function and then wrapping it with `weave.op()` to enable automatic logging of calls and performance tracking. Limitations in cost management currently include the inability to customize logging configurations efficiently and potential challenges in monitoring resource utilization across versioned functions. Additionally, without proper initialization with `weave.init()`, functions won't participate in versioning and tracking.","TypeScript can be used with Weave ops by importing the Weave library and defining functions that can be tracked. For example, a function `trackMe` can be defined and then wrapped with `weave.op` to create a trackable operation. However, there are limitations in TypeScript regarding cost management features. Specifically, the ability to add and query custom costs, which is available in Python, is not yet available in TypeScript.",0.5,0.4,0.6,0.9999999999,0.4,0.9916160937535786,0.16666666638888888
"How can the AnnotationSpec class be used to create and modify human annotation scorers for analyzing call interactions, and how are these annotations displayed in the call details page?","['Open the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\n5. Make an annotation. 6. Click Save. 7. In the call details page, click Feedback to view the calls table. The new annotation displays in the table. You can also view the annotations in the Annotations column in the call table in Traces.\n\nRefresh the call table to view the most up-to-date information.\n\nCreate a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.\n\nIn the following example, a human annotator is asked to select which type of document the LLM ingested. As such, the Type selected for the score configuration is an enum containing the possible document types.\n\nUse the human annotation scorer in the UI\n\nOnce you create a human annotation scorer, it will automatically display in the Feedback sidebar of the call details page with the configured options. To use the scorer, do the following:\n\nIn the sidebar, navigate to Traces\n\nFind the row for the call that you want to add a human annotation to.\n\nOpen the call details page.\n\nIn the upper right corner, click the Show feedback button.\n\nYour available human annotation scorers display in the sidebar.\n\nDelete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\nAdd human annotations\n\nHuman annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the UI or the API. Then, you can use the scorer in the UI to make annotations, and modify your annotation scorers using the API.\n\nCreate a human annotation scorer in the UI\n\nTo create a human annotation scorer in the UI, do the following:\n\nIn the sidebar, navigate to Scorers.\n\nIn the upper right corner, click + Create scorer.\n\nIn the configuration page, set:\n\nScorer type to Human annotation\n\nName\n\nDescription\n\nType, which determines the type of feedback that will be collected, such as boolean or integer.\n\nClick Create scorer. Now, you can use your scorer to make annotations.\n\nImport the AnnotationSpec class from weave.flow.annotation_spec\n\nUse the save method on the weave client to create the scorer.\n\nIn the following example, two scorers are created. The first scorer, Temperature, is used to score the perceived temperature of the LLM call. The second scorer, Tone, is used to score the tone of the LLM response. Each scorer is created using save with an associated object ID (temperature-scorer and tone-scorer).\n\napi = weave.init(""feedback-example"")\n\nspec1 = AnnotationSpec(\n  name=""Temperature"",\n  description=""The perceived temperature of the llm call"",\n  field_schema={\n    ""type"": ""number"",\n    ""minimum"": -1,\n    ""maximum"": 1,\n  }\n)\nspec2 = AnnotationSpec(\n  name=""Tone"",\n  description=""The tone of the llm response"",\n  field_schema={\n    ""type"": ""string"",\n    ""enum"": [""Aggressive"", ""Neutral"", ""Polite"", ""N/A""],\n  },\n)\napi.save(spec1, ""temperature-scorer"")\napi.save(spec2, ""tone-scorer"")\n```\n\nModify a human annotation scorer using the API']","The AnnotationSpec class can be used to create and modify human annotation scorers by defining properties such as name, description, and type, and saving them through the API. Once created, these scorers appear in the Feedback sidebar on the call details page, allowing users to make annotations. Annotations are displayed in the calls table under the Annotations column, and can be updated by refreshing the call table.","The AnnotationSpec class, imported from weave.flow.annotation_spec, is used to create human annotation scorers by defining specific attributes such as name, description, and field schema. For example, a scorer named 'Temperature' can be created to assess the perceived temperature of an LLM call, and another named 'Tone' to evaluate the tone of the LLM response. These scorers are saved using the save method on the weave client with unique object IDs. Once created, these scorers can be modified using the API. In the call details page, users can click the Show feedback button to display available human annotation scorers in the sidebar. Annotations can be made and saved, and they will appear in the calls table under the Feedback section. The annotations are also visible in the Annotations column in the call table in Traces, and refreshing the call table ensures the most up-to-date information is displayed.",1.0,0.5,0.5,0.9999999999,0.3333333333333333,0.93521214908138,0.6190476187528344
how ops and op calls work with weave?,"['FAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nOp call hierarchy - When an Op is called within the context of another Op executing, this relationship is captured, even in cases where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a ""Trace tree"".\n\nExecution status and exceptions - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\nSystem information - Weave may capture information about which operating system the client is running on including detailed version information.\n\nClient information - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.\n\nimport Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init(\'intro-example\')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don\'t call `weave.init(\'your-project-name\')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from \'weave\'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)\n\nCode capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.']","Weave manages operations (Ops) by designating functions with the `@weave.op()` decorator, allowing for automatic logging of calls, inputs, outputs, and execution status. When an Op is executed, it captures detailed information such as call hierarchy, timing, and any exceptions that occur. This data supports analysis and aids in tracing the execution flow, creating a ""Trace tree,"" which reflects the relationships between nested Op calls.","Ops in Weave are versioned functions that automatically log all calls. When an Op is called, it creates a new version if the code has changed since the last call, logging the inputs and outputs. If an Op is called within another Op, this relationship is captured to provide a 'Trace tree'. Weave also tracks execution status, exceptions, system information, client information, timing, and token usage.",1.0,0.46,1.0,0.9999999999,0.6,0.906998270435493,0.7499999981250001
"How can the Python SDK be used to redact PII from traces in Weights & Biases, and what are the implications of using object references in this context?","['Redact PII from Traces\n\n:::important This feature is only available for Enterprise users, and is only accessible via the Python SDK. :::\n\nSome organizations process Personally Identifiable Information (PII) such as names, phone numbers, and email addresses in their Large Language Model (LLM) workflows. Storing this data in Weights & Biases (W&B) Weave poses compliance and security risks.\n\nThe Sensitive Data Protection feature allows you to automatically redact Personally Identifiable Information (PII) from a trace before it is sent to Weave servers. This feature integrates Microsoft Presidio into the Weave Python SDK, which means that you can control redaction settings at the SDK level.\n\nThe Sensitive Data Protection feature introduces the following functionality to the Python SDK:\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.\n\nFor a full list of the entities that can be detected and redacted, see PII entities supported by Presidio.\n\nEntities redacted by default\n\nThe following entities are automatically redacted when PII redaction is enabled:\n\nCREDIT_CARD\n\nCRYPTO\n\nEMAIL_ADDRESS\n\nES_NIF\n\nFI_PERSONAL_IDENTITY_CODE\n\nIBAN_CODE\n\nIN_AADHAAR\n\nIN_PAN\n\nIP_ADDRESS\n\nLOCATION\n\nPERSON\n\nPHONE_NUMBER\n\nUK_NHS\n\nUK_NINO\n\nUS_BANK_NUMBER\n\nUS_DRIVER_LICENSE\n\nUS_PASSPORT\n\nUS_SSN\n\nUsage information\n\nThis feature is only available in the Python SDK.\n\nEnabling redaction increases processing time due to the Presidio dependency.\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.\n\nCustomizable redaction fields using the configurable redact_pii_fields setting.\n\nEnable PII redaction\n\nTo get started with the Sensitive Data Protection feature in Weave, complete the following steps:\n\nInstall the required dependencies:\n\nbash pip install presidio-analyzer presidio-anonymizer\n\nModify your weave.init call to enable redaction. When redact_pii=True, common entities are redacted by default:\n\n```python import weave\n\nweave.init(""my-project"", settings={""redact_pii"": True}) ```\n\n(Optional) Customize redaction fields using the redact_pii_fields parameter:\n\npython weave.init(""my-project"", settings={""redact_pii"": True, ""redact_pii_fields""=[""CREDIT_CARD"", ""US_SSN""]})\n\nFor a full list of the entities that can be detected and redacted, see PII entities supported by Presidio.\n\nEntities redacted by default']","The Python SDK for Weights & Biases allows you to redact Personally Identifiable Information (PII) by using the `redact_pii` setting during the `weave.init` call. This feature automatically redacts common entities when enabled, utilizing Microsoft Presidio for PII detection and redaction. When using object references, it enables better tracking and management of data changes over time, enhancing compliance and security in handling sensitive data.","The Python SDK can be used to redact Personally Identifiable Information (PII) from traces in Weights & Biases by utilizing the Sensitive Data Protection feature, which integrates Microsoft Presidio. This feature allows users to automatically redact PII by toggling the redact_pii setting on in the weave.init call. This ensures that sensitive information is not stored in Weave, mitigating compliance and security risks. In the context of using object references, the Python SDK allows for the construction and management of object references, such as fetching and deleting objects. A fully qualified weave object ref URI is used to manage these references, which can be crucial when handling sensitive data, as accessing a deleted object will result in a `DeletedRef` object, ensuring that sensitive information is not inadvertently accessed.",0.6,0.37,0.8,0.9999999999,0.4,0.9073211354944699,0.5833333328472222
How does the integration of the SDK in Weave's feedback system enhance the process of monitoring and optimizing code performance through human annotations and feedback management?,"['import Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nFeedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\nBuild evaluation datasets for performance monitoring.\n\nIdentify and resolve LLM content issues effectively.\n\nGather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weaves feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\nProvide feedback in the UI\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nFrom the call details page\n\nIn the sidebar, navigate to Traces.\n\nFind the row for the call that you want to add feedback to.\n\nOpen the call details page.\n\nSelect the Feedback column for the call.\n\nAdd, view, or delete feedback:\n\nAdd and view feedback using the icons located in the upper right corner of the call details feedback view.\n\nView and delete feedback from the call details feedback table. Delete feedback by clicking the trashcan icon in the rightmost column of the appropriate feedback row.\n\nUse the icons\n\nYou can add or remove a reaction, and add a note using the icons that are located in both the call table and individual call details pages.\n\nCall table: Located in Feedback column in the appropriate row in the call table.\n\nCall details page: Located in the upper right corner of each call details page.\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page']","The integration of the SDK in Weave's feedback system enhances monitoring and optimizing code performance by enabling users to submit feedback programmatically, which streamlines the collection of human annotations. This allows teams to build evaluation datasets efficiently, identify and resolve issues, and gather examples for tasks like fine-tuning. Overall, it creates a more responsive and data-driven feedback management process.","The integration of the SDK in Weave's feedback system enhances the process of monitoring and optimizing code performance by allowing users to provide call feedback directly through the UI or programmatically via the SDK. This system supports various feedback types, including emoji reactions, textual comments, and structured data, which are crucial for building evaluation datasets for performance monitoring. Additionally, it enables the identification and resolution of LLM content issues and the gathering of examples for advanced tasks like fine-tuning. Human annotations further contribute to detailed evaluations, making the feedback system robust and efficient for performance optimization.",1.0,0.47,0.5,0.9999999999,0.0,0.9767698904257877,0.9999999975
"Howw doo youu enablee andd customizee PII redactionn usingg Presidioo in Weavee, andd whatare the defaultt entitiess thatt gett redacted?","['A redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.\n\nCustomizable redaction fields using the configurable redact_pii_fields setting.\n\nEnable PII redaction\n\nTo get started with the Sensitive Data Protection feature in Weave, complete the following steps:\n\nInstall the required dependencies:\n\nbash pip install presidio-analyzer presidio-anonymizer\n\nModify your weave.init call to enable redaction. When redact_pii=True, common entities are redacted by default:\n\n```python import weave\n\nweave.init(""my-project"", settings={""redact_pii"": True}) ```\n\n(Optional) Customize redaction fields using the redact_pii_fields parameter:\n\npython weave.init(""my-project"", settings={""redact_pii"": True, ""redact_pii_fields""=[""CREDIT_CARD"", ""US_SSN""]})\n\nFor a full list of the entities that can be detected and redacted, see PII entities supported by Presidio.\n\nEntities redacted by default\n\nFor a full list of the entities that can be detected and redacted, see PII entities supported by Presidio.\n\nEntities redacted by default\n\nThe following entities are automatically redacted when PII redaction is enabled:\n\nCREDIT_CARD\n\nCRYPTO\n\nEMAIL_ADDRESS\n\nES_NIF\n\nFI_PERSONAL_IDENTITY_CODE\n\nIBAN_CODE\n\nIN_AADHAAR\n\nIN_PAN\n\nIP_ADDRESS\n\nLOCATION\n\nPERSON\n\nPHONE_NUMBER\n\nUK_NHS\n\nUK_NINO\n\nUS_BANK_NUMBER\n\nUS_DRIVER_LICENSE\n\nUS_PASSPORT\n\nUS_SSN\n\nUsage information\n\nThis feature is only available in the Python SDK.\n\nEnabling redaction increases processing time due to the Presidio dependency.\n\nRedact PII from Traces\n\n:::important This feature is only available for Enterprise users, and is only accessible via the Python SDK. :::\n\nSome organizations process Personally Identifiable Information (PII) such as names, phone numbers, and email addresses in their Large Language Model (LLM) workflows. Storing this data in Weights & Biases (W&B) Weave poses compliance and security risks.\n\nThe Sensitive Data Protection feature allows you to automatically redact Personally Identifiable Information (PII) from a trace before it is sent to Weave servers. This feature integrates Microsoft Presidio into the Weave Python SDK, which means that you can control redaction settings at the SDK level.\n\nThe Sensitive Data Protection feature introduces the following functionality to the Python SDK:\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page']","To enable and customize PII redaction in Weave, set the `redact_pii` parameter to `True` in the `weave.init` call. You can further customize by specifying fields in the `redact_pii_fields` setting. By default, entities such as EMAIL_ADDRESS, PHONE_NUMBER, and CREDIT_CARD will be redacted automatically.","To enable and customize PII redaction using Presidio in Weave, you need to install the required dependencies by running the command `pip install presidio-analyzer presidio-anonymizer`. Then, modify your `weave.init` call to enable redaction by setting `redact_pii=True`, which will automatically redact common entities by default. You can further customize the redaction fields using the `redact_pii_fields` parameter, for example: `weave.init(""my-project"", settings={""redact_pii"": True, ""redact_pii_fields"":[""CREDIT_CARD"", ""US_SSN""]})`. The default entities that get redacted when PII redaction is enabled include CREDIT_CARD, CRYPTO, EMAIL_ADDRESS, ES_NIF, FI_PERSONAL_IDENTITY_CODE, IBAN_CODE, IN_AADHAAR, IN_PAN, IP_ADDRESS, LOCATION, PERSON, PHONE_NUMBER, UK_NHS, UK_NINO, US_BANK_NUMBER, US_DRIVER_LICENSE, US_PASSPORT, and US_SSN.",1.0,0.6,1.0,0.9999999999,0.0,0.9313857397554189,0.919999999632
What is the role of Tabs in the provided code context?,"[""import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nFeedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\nBuild evaluation datasets for performance monitoring.\n\nIdentify and resolve LLM content issues effectively.\n\nGather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weaves feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\nProvide feedback in the UI\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nimport Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init('intro-example')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don't call `weave.init('your-project-name')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from 'weave'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)\n\nCode capture - Weave captures a representation of the Op's source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.""]","The role of `Tabs` in the provided code context is to create a tabbed interface for displaying different sections of content. It allows users to switch between various `TabItem` components, enhancing the organization and presentation of information within the UI. This facilitates a more streamlined user experience when interacting with multiple pieces of related content.","In the provided code context, Tabs is imported from '@theme/Tabs', indicating its use as a component or module related to theming, likely for organizing or displaying content in a tabbed interface.",1.0,0.22,0.0,0.0,0.0,0.9658023438937221,0.4999999975
Is the feature currently available in TypeScript?,"['```plaintext\nThis feature is not available in TypeScript yet.  Stay tuned!\n```\n\nPurging a custom cost\n\n```python\nimport weave\n\nclient = weave.init(""my_custom_cost_model"")\n\ncosts = client.query_costs(llm_ids=[""your_model_name""])\nclient.purge_costs([cost.id for cost in costs])\n```\n\nCalculating costs for a Project\n\n```python\nimport weave\n\nweave.init(""project_costs"")\n@weave.op()\ndef get_costs_for_project(project_name: str):\n    total_cost = 0\n    requests = 0\n\n    client = weave.init(project_name)\n    # Fetch all the calls in the project\n    calls = list(\n        client.get_calls(filter={""trace_roots_only"": True}, include_costs=True)\n    )\n\nimport Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nFeedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\nBuild evaluation datasets for performance monitoring.\n\nIdentify and resolve LLM content issues effectively.\n\nGather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weaves feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\nProvide feedback in the UI\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:']","No, the feature is not currently available in TypeScript. Stay tuned for updates!",This feature is not available in TypeScript yet. Stay tuned!,1.0,1.0,1.0,0.9999999999,0.0,1.0,0.9999999900000002
How is Python used in the context of Weave ops?,"['```typescript showLineNumbers\nimport * as weave from \'weave\'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)\n\n\n// You can also do this inline, which may be more convenient\nconst trackMeInline = weave.op((v: number) => v + 5)\ntrackMeInline(15)\n```\n\nCustomize display names\n\n```python\n@weave.op(name=""custom_name"")\ndef func():\n    ...\n```\n\nCustomize logged inputs and outputs\n\n`postprocess_inputs` takes in a dict where the keys are the argument names and the values are the argument values, and returns a dict with the transformed inputs.\n\n`postprocess_output` takes in any value which would normally be returned by the function and returns the transformed output.\n\n```py\nfrom dataclasses import dataclass\nfrom typing import Any\nimport weave\n\n@dataclass\nclass CustomObject:\n    x: int\n    secret_password: str\n\ndef postprocess_inputs(inputs: dict[str, Any]) -> dict[str, Any]:\n    return {k:v for k,v in inputs.items() if k != ""hide_me""}\n\nimport Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init(\'intro-example\')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don\'t call `weave.init(\'your-project-name\')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from \'weave\'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nCode capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.']","Python is used in Weave ops by defining functions with the `@weave.op()` decorator, which allows for automatic logging of calls to these functions, including their inputs and outputs. This setup enables version control of the function's code and keeps track of changes over time whenever the function is called. Additionally, developers can customize the logging of inputs and outputs for each operation.","In the context of Weave ops, Python is used to define functions that are decorated with `@weave.op()`, which automatically logs all calls and creates a new op version if the code changes. The example provided shows a Python function `track_me` that adds 5 to its input and is tracked using Weave.",1.0,0.44,1.0,0.9999999999,0.5,0.9917088814502321,0.0
Waht is Weave?,"['Objects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nHow is Weave data ingestion calculated?\n\nWe define ingested bytes as bytes that we receive, process, and store on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information you explicitly log to Weave, but does not include communication overhead (e.g., HTTP headers) or any other data that is not placed in long-term storage. We count bytes as ""ingested"" only once at the time they are received and stored.']","Weave is a system that provides tracing capabilities for tracking and versioning objects and function calls in applications. Its features allow users to monitor data flow, debug interactions, and maintain a history of modifications for better development and insights. This is particularly useful for building robust AI-powered systems.","Weave is a system used for tracing operations, where you can control the sampling rate of call traces and manage call link outputs.",0.0,0.17,1.0,0.9999999999,1.0,0.9346687070707028,0.249999999375
Could you elaborate on how Weave captures information for a function and the level of control it offers over the logging process?,"['FAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nCode capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page']","Weave captures detailed information for a function designated as a Weave Op, either manually or automatically, including function performance, inputs, outputs, and source code representation. It offers fine-grained control over logging, allowing you to customize what gets logged, including inputs and outputs. This flexibility enables the monitoring and debugging of applications while ensuring accurate versioning and reproducibility.","A function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default.",1.0,0.36,1.0,0.9999999999,0.5714285714285714,0.838296329965447,0.4999999975
What Weave do with code capture and how it help with Op versioning?,"['Code capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page']","Weave captures a representation of the Op's source code, including inline comments and variable values, which aids in understanding function evaluations over time. This code capture is integral to Op versioning, enabling users to track changes and behaviors even if modifications are not saved in the source control system. If code capture is disabled, a hash value will be used instead to represent the function.","Weave captures a representation of the Op's source code, including inline comments and the value of variables or the source of non-Op functions that were called. This allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time.",1.0,0.62,0.8571428571428571,0.9999999999,0.14285714285714285,0.9101432052569115,0.2222222219753086
What Trace tree do?,"['Tracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nOp call hierarchy - When an Op is called within the context of another Op executing, this relationship is captured, even in cases where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a ""Trace tree"".\n\nExecution status and exceptions - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\nSystem information - Weave may capture information about which operating system the client is running on including detailed version information.\n\nClient information - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.']","A Trace tree in Weave captures the hierarchical relationships between function calls, specifically when an Op is executed within the context of another Op. This allows for detailed analysis of how functions interact with each other, providing insights into the flow of execution. Additionally, it helps in monitoring execution status, exceptions, and performance metrics.","The Trace tree provides a relationship between Op calls, capturing when an Op is called within the context of another Op executing, even if there is an intermediate non-Op function executing.",1.0,0.4,0.42857142857142855,0.9999999999,0.2857142857142857,0.9189132819169706,0.999999995
What Weave do with info it logs?,"['FAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nHow can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_system_info"": False}).\n\nHow can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_client_info"": False}).\n\nWill Weave affect my function\'s execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM. To minimize Weave\'s impact on the speed of your Op\'s execution, its network activity happens on a background thread. When your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\nHow is Weave data ingestion calculated?\n\nHow is Weave data ingestion calculated?\n\nWe define ingested bytes as bytes that we receive, process, and store on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information you explicitly log to Weave, but does not include communication overhead (e.g., HTTP headers) or any other data that is not placed in long-term storage. We count bytes as ""ingested"" only once at the time they are received and stored.\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page']","Weave logs detailed information during the execution of designated functions (Ops) to support analysis. This includes trace metadata, LLM inputs/outputs, and any explicitly logged data. The logged information is ingested and stored, enabling tracking of changes and maintaining a history of object modifications.","Weave may compute derived information from the raw information logged, such as calculating a cost estimate based on token usage and knowledge of the model used. It also aggregates some information over calls.",0.0,0.17,0.6,0.9999999999,0.0,0.8865912366493364,0.0
LLM slow down calls?,"['import Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nFeedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\nBuild evaluation datasets for performance monitoring.\n\nIdentify and resolve LLM content issues effectively.\n\nGather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weaves feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\nProvide feedback in the UI\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nHow can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_system_info"": False}).\n\nHow can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_client_info"": False}).\n\nWill Weave affect my function\'s execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM. To minimize Weave\'s impact on the speed of your Op\'s execution, its network activity happens on a background thread. When your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\nHow is Weave data ingestion calculated?\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nTiming - The execution start and end time is captured and also used for latency calculations.\n\nToken usage - In some integrations LLM token usage counts may be automatically logged.\n\nUser and run context - Logging is associated with a W&B user account. That will be captured along with any wandb Run context.\n\nDerived information - Weave may compute derived information from the raw information logged, for example a cost estimate may be calculated based on token usage and knowledge of the model used. Weave also aggregates some information over calls.\n\nAdditional information you choose - You can choose to log custom attributes as part of your call or attach feedback to a call.\n\nHow can I disable code capture?\n\nYou can disable code capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_code"": False}). You can also use the environment variable WEAVE_CAPTURE_CODE=false.\n\nHow can I disable system information capture?']","Weave's overhead from logging is typically negligible compared to making a call to an LLM, so it shouldn't significantly slow down execution. Its network activity occurs on a background thread to minimize any impact on function speed. However, there may be a brief pause when the program exits as it logs any remaining data.",The overhead of Weave logging is typically negligible compared to making a call to an LLM.,1.0,0.57,1.0,0.9999999999,0.75,0.7963313963169568,0.999999995
How does Weave calculate data ingestion?,"['How is Weave data ingestion calculated?\n\nWe define ingested bytes as bytes that we receive, process, and store on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information you explicitly log to Weave, but does not include communication overhead (e.g., HTTP headers) or any other data that is not placed in long-term storage. We count bytes as ""ingested"" only once at the time they are received and stored.\n\nHow can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_system_info"": False}).\n\nHow can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: weave.init(""entity/project"", settings={""capture_client_info"": False}).\n\nWill Weave affect my function\'s execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM. To minimize Weave\'s impact on the speed of your Op\'s execution, its network activity happens on a background thread. When your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\nHow is Weave data ingestion calculated?\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:']","Weave calculates data ingestion based on the total number of bytes received, processed, and stored, including trace metadata and logged information, but excluding communication overhead. Ingested bytes are only counted once at the moment of receipt and storage.","Weave calculates data ingestion by counting the bytes that are received, processed, and stored on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information explicitly logged to Weave. It does not include communication overhead or data not placed in long-term storage. Bytes are counted as 'ingested' only once at the time they are received and stored.",1.0,0.75,0.75,0.9999999999,0.0,1.0,0.14285714265306124
Wht is the use of Tabs in the code?,"[""import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nFeedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\nBuild evaluation datasets for performance monitoring.\n\nIdentify and resolve LLM content issues effectively.\n\nGather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weaves feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\nProvide feedback in the UI\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nCode capture - Weave captures a representation of the Op's source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.\n\nimport Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';\n\nOps\n\nA Weave op is a versioned function that automatically logs all calls.\n\n```python showLineNumbers\nimport weave\n\n@weave.op()\ndef track_me(v):\n    return v + 5\n\nweave.init('intro-example')\ntrack_me(15)\n```\n\nCalling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n:::note\nFunctions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don't call `weave.init('your-project-name')` before calling them.\n:::\n\nOps can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n```typescript showLineNumbers\nimport * as weave from 'weave'\n\nfunction trackMe(v: number) {\n    return v + 5\n}\n\nconst trackMeOp = weave.op(trackMe)\ntrackMeOp(15)\n\nObjects\n\nObjects form Weave's extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application's behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page""]","The `Tabs` component is likely used to create a tabbed navigation interface in the code, allowing users to switch between different content sections easily. Each `TabItem` represents an individual tab within the `Tabs` component. This structure enhances user experience by organizing content in a compact and accessible manner.",Tabs are imported from '@theme/Tabs' and are likely used for organizing or displaying content in a tabbed interface.,0.0,0.29,0.0,0.0,0.0,0.8801008662281932,0.0
What does a fully qualified weave object ref URI look like?,"['Refs can be constructed with a few different styles\n\nweave.ref(<name>): requires weave.init(<project>) to have been called. Refers to the "":latest"" version\n\nweave.ref(<name>:<version>): requires weave.init(<project>) to have been called.\n\nweave.ref(<fully_qualified_ref_uri>): can be constructed without calling weave.init\n\nGetting an object back\n\nYou can construct a ref and then fetch the object back.\n\n```python\nweave.init(\'intro-example\')\ncat_names = weave.ref(\'cat-names\').get()\n```\n\nDeleting an object\n\n```python\nweave.init(\'intro-example\')\ncat_names_ref = weave.ref(\'cat-names:v1\')\ncat_names_ref.delete()\n```\n\nTrying to access a deleted object will result in an error. Resolving an object that has a reference to a deleted object will return a `DeletedRef` object in place of the deleted object.\n\nRef styles\n\nA fully qualified weave object ref uri looks like this:\n\nweave:///<entity>/<project>/object/<object_name>:<object_version>\n\nentity: wandb entity (username or team)\n\nproject: wandb project\n\nobject_name: object name\n\nobject_version: either a version hash, a string like v0, v1..., or an alias like "":latest"". All objects have the "":latest"" alias.\n\nRefs can be constructed with a few different styles\n\nweave.ref(<name>): requires weave.init(<project>) to have been called. Refers to the "":latest"" version\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:']","A fully qualified weave object ref URI looks like this: `weave:///<entity>/<project>/object/<object_name>:<object_version>`. Here, `<entity>` is the wandb entity (username or team), `<project>` is the wandb project, `<object_name>` is the object name, and `<object_version>` can be a version hash, a string like v0 or v1, or an alias like "":latest"". This structure allows reference to specific versions of objects within Weave.","A fully qualified weave object ref URI looks like this: weave:///<entity>/<project>/object/<object_name>:<object_version>. The entity is a wandb entity (username or team), the project is a wandb project, the object_name is the name of the object, and the object_version can be a version hash, a string like v0, v1..., or an alias like "":latest"".",1.0,1.0,1.0,0.9999999999,0.16666666666666666,0.9807484984677212,0.0
What are the tracing capabilities of Weave in AI-powered applications?,"['Tracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nRedact PII from Traces\n\n:::important This feature is only available for Enterprise users, and is only accessible via the Python SDK. :::\n\nSome organizations process Personally Identifiable Information (PII) such as names, phone numbers, and email addresses in their Large Language Model (LLM) workflows. Storing this data in Weights & Biases (W&B) Weave poses compliance and security risks.\n\nThe Sensitive Data Protection feature allows you to automatically redact Personally Identifiable Information (PII) from a trace before it is sent to Weave servers. This feature integrates Microsoft Presidio into the Weave Python SDK, which means that you can control redaction settings at the SDK level.\n\nThe Sensitive Data Protection feature introduces the following functionality to the Python SDK:\n\nA redact_pii setting, which can be toggled on or off in the weave.init call to enable PII redaction.\n\nAutomatic redaction of common entities when redact_pii = True.']","Weave offers robust tracing capabilities for AI-powered applications, enabling the tracking and versioning of objects and function calls. Its key features include Calls for analyzing data flow, Ops for monitoring function performance, and Objects for versioning runtime data structures. This system enhances monitoring, debugging, and iterative development, improving application performance and robustness.","Weave provides powerful tracing capabilities to track and version objects and function calls in AI-powered applications. This system enables better monitoring, debugging, and iterative development by allowing users to track insights between commits.",1.0,0.55,0.8571428571428571,0.9999999999,0.5714285714285714,0.9298542979728183,0.999999995
Wht is the purpse of Weave's objcts?,"['Objects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nFAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\nWhat information does Weave capture for a function?\n\nA function can be designated as a Weave Op either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\nCode capture - Weave captures a representation of the Op\'s source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\nFunction name, inputs, and outputs - The name of the function will be captured but can be overridden. A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you customize the logging of inputs and outputs - you can specify a function to add/remove/modify what is logged.']","The purpose of Weave's objects is to form an extensible serialization layer that automatically versions runtime objects, often used as inputs and outputs of function calls. This functionality allows developers to track changes in data structures over time, maintain a clear history of modifications, and easily revert to previous versions when needed. Ultimately, it enhances monitoring, debugging, and iterative development of AI-powered applications.","Objects form Weave's extensible serialization layer, automatically versioning runtime objects, which allows you to track changes in data structures over time, maintain a clear history of object modifications, and easily revert to previous versions when needed.",1.0,0.71,1.0,0.9999999999,0.4444444444444444,0.968042863816819,0.0
Wht is LLM?,"['import Tabs from \'@theme/Tabs\'; import TabItem from \'@theme/TabItem\';\n\nFeedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\nBuild evaluation datasets for performance monitoring.\n\nIdentify and resolve LLM content issues effectively.\n\nGather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weaves feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\nProvide feedback in the UI\n\nProvide feedback via the SDK\n\nAdd human annotations\n\nProvide feedback in the UI\n\nIn the Weave UI, you can add and view feedback from the call details page or using the icons.\n\nHow is Weave data ingestion calculated?\n\nWe define ingested bytes as bytes that we receive, process, and store on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information you explicitly log to Weave, but does not include communication overhead (e.g., HTTP headers) or any other data that is not placed in long-term storage. We count bytes as ""ingested"" only once at the time they are received and stored.\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\nTrack changes in data structures over time\n\nMaintain a clear history of object modifications\n\nEasily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application\'s behavior, streamline your development process, and build more robust AI-powered systems.\n\nFAQs\n\nFor answers to common questions about Weave tracing, see the FAQs page\n\nTracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to ""track insights between commits.""\n\nKey Tracing Features\n\nWeave\'s tracing functionality comprises three main components:\n\nCalls\n\nCalls trace function calls, inputs, and outputs, enabling you to:\n\nAnalyze data flow through your application\n\nDebug complex interactions between components\n\nOptimize application performance based on call patterns\n\nOps\n\nOps are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\nMonitor function performance and behavior\n\nMaintain a record of function modifications\n\nEnsure experiment reproducibility\n\nObjects\n\nObjects form Weave\'s extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:']","LLM stands for Large Language Model, a type of artificial intelligence designed to understand and generate human-like text. These models can be evaluated through feedback mechanisms to improve their performance and address content issues. Weave offers tools for collecting and analyzing feedback on LLM applications to enhance their capabilities.","LLM applications require robust tooling to collect and analyze feedback, which Weave provides through an integrated feedback system.",1.0,0.43,0.5714285714285714,0.0,0.2857142857142857,0.8987830125492001,0.4999999975
